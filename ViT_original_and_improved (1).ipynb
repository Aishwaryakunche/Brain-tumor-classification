{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Training a vision transformer without batch normalisation and weight decay (L2 regularisation)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My Drive/DL project_aug1/DL project\n",
        "!ls\n",
        "\n",
        "# This model is trained using tensor flow using Keras module. the following modules are imported\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense, Input, Reshape\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "tensorboard = TensorBoard(log_dir='./ViT', histogram_freq=0, write_graph=True, write_images=False)\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "\n",
        "image_size = 224\n",
        "IMG_SHAPE = (image_size, image_size, 3)\n",
        "\n",
        "# Load the Vision Transformer model from TensorFlow Hub\n",
        "vit_model_url = \"https://tfhub.dev/sayakpaul/vit_b16_fe/1\"\n",
        "base_model = hub.KerasLayer(vit_model_url, trainable=True)\n",
        "\n",
        "# Building the model using the Functional API\n",
        "# Define the input layer\n",
        "input_tensor = Input(shape=IMG_SHAPE)\n",
        "\n",
        "# Creating a function to apply the base_model\n",
        "def apply_base_model(inputs):\n",
        "    return base_model(inputs, training=False) # Set training=False during inference\n",
        "\n",
        "# Passing the input through the function to get the output\n",
        "x = tf.keras.layers.Lambda(apply_base_model)(input_tensor)\n",
        "\n",
        "# Reshaping the output of the base_model to 4D before applying GlobalAveragePooling2D\n",
        "x = Reshape((1, 1, 768))(x)  # Reshape to (batch_size, 1, 1, features)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x) # Now this layer will work correctly\n",
        "x = Dropout(0.4)(x) # Applying a dropout of 0.4 or 40%\n",
        "output_tensor = Dense(4, activation='softmax')(x)  # Adjusting the number of classes\n",
        "\n",
        "model = Model(inputs=input_tensor, outputs=output_tensor)  # Creating the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "\n",
        "# Preparing the data by data Augumentation usingImage data generator predefined function\n",
        "train_datagen = ImageDataGenerator(rescale=0.2,\n",
        "                                   rotation_range=30,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   validation_split=0.2)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory('/content/gdrive/My Drive/DL project_aug1/DL project/training',\n",
        "                                                    target_size=(image_size, image_size),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='sparse',\n",
        "                                                    subset='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory('/content/gdrive/My Drive/DL project_aug1/DL project/testing',\n",
        "                                                         target_size=(image_size, image_size),\n",
        "                                                         batch_size=32,\n",
        "                                                         class_mode='sparse',\n",
        "                                                         subset='validation')\n",
        "\n",
        "# Fitting the model\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "                    epochs=7,\n",
        "                    callbacks=[tensorboard, es])\n",
        "\n",
        "# Evaluating the model for validating results.\n",
        "scores = model.evaluate(validation_generator, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n",
        "\n",
        "# Generation of classification report\n",
        "y_pred = model.predict(validation_generator, batch_size=64, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "print(classification_report(validation_generator.classes, y_pred_bool, target_names=train_generator.class_indices.keys()))\n",
        "\n",
        "# Saving the model\n",
        "model.save(\"ViT_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ7pSw70whXS",
        "outputId": "120a3355-9c41-4628-8e28-dab7be6f520a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/DL project_aug1/DL project\n",
            "ResNet50\t       testing\t X_test.pickle\t Y_test.pickle\n",
            "ResNet50accuracy87.h5  training  X_train.pickle  Y_train.pickle\n",
            "Found 2297 images belonging to 4 classes.\n",
            "Found 78 images belonging to 4 classes.\n",
            "Epoch 1/7\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1733s\u001b[0m 23s/step - accuracy: 0.2957 - loss: 2.5028 - val_accuracy: 0.3906 - val_loss: 1.9681\n",
            "Epoch 2/7\n",
            "\u001b[1m 1/71\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23:31\u001b[0m 20s/step - accuracy: 0.3438 - loss: 1.7839"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 208ms/step - accuracy: 0.3438 - loss: 1.7839 - val_accuracy: 0.1429 - val_loss: 2.6588\n",
            "Epoch 3/7\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1579s\u001b[0m 22s/step - accuracy: 0.4579 - loss: 1.6184 - val_accuracy: 0.2969 - val_loss: 2.1220\n",
            "Epoch 4/7\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 140ms/step - accuracy: 0.4688 - loss: 1.6040 - val_accuracy: 0.2857 - val_loss: 1.6685\n",
            "Epoch 5/7\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1598s\u001b[0m 22s/step - accuracy: 0.4773 - loss: 1.5029 - val_accuracy: 0.2812 - val_loss: 2.3666\n",
            "Epoch 6/7\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 116ms/step - accuracy: 0.4688 - loss: 1.5198 - val_accuracy: 0.3571 - val_loss: 1.9521\n",
            "Epoch 7/7\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1621s\u001b[0m 22s/step - accuracy: 0.5408 - loss: 1.3091 - val_accuracy: 0.3750 - val_loss: 2.0978\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 15s/step - accuracy: 0.2468 - loss: 2.1228\n",
            "Test loss: 2.1601457595825195\n",
            "Test accuracy: 0.24358974397182465\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 15s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      glioma       0.50      0.05      0.09        20\n",
            "  meningioma       0.20      0.13      0.16        23\n",
            "    no_tumor       0.31      0.71      0.43        21\n",
            "   pituitary       0.15      0.14      0.15        14\n",
            "\n",
            "    accuracy                           0.27        78\n",
            "   macro avg       0.29      0.26      0.21        78\n",
            "weighted avg       0.30      0.27      0.21        78\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Modifying the model for improving accuracy using learning rate scheduler, batch normalisation, weight decay L2 regularisation\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My Drive/DL project_aug1/DL project\n",
        "!ls\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense, Input, Reshape\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "tensorboard = TensorBoard(log_dir='./ViT', histogram_freq=0, write_graph=True, write_images=False)\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
        "\n",
        "image_size = 224\n",
        "IMG_SHAPE = (image_size, image_size, 3)\n",
        "\n",
        "# Loading the Vision Transformer model from TensorFlow Hub\n",
        "vit_model_url = \"https://tfhub.dev/sayakpaul/vit_b16_fe/1\"\n",
        "base_model = hub.KerasLayer(vit_model_url, trainable=True)\n",
        "\n",
        "# Build the model using the Functional API\n",
        "# Define the input layer\n",
        "input_tensor = Input(shape=IMG_SHAPE)\n",
        "\n",
        "# Create a function to apply the base_model\n",
        "def apply_base_model(inputs):\n",
        "    return base_model(inputs, training=False) # Set training=False during inference\n",
        "\n",
        "# Pass the input through the function to get the output\n",
        "x = tf.keras.layers.Lambda(apply_base_model)(input_tensor)\n",
        "\n",
        "# Reshape the output of the base_model to 4D before applying GlobalAveragePooling2D\n",
        "x = Reshape((1, 1, 768))(x)  # Reshape to (batch_size, 1, 1, features)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x) # Now this layer will work correctly\n",
        "x = Dropout(0.5)(x)  # Increase dropout rate for better regularization\n",
        "output_tensor = Dense(4, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation='softmax')(x)  # Adjust the number of classes and add L2 regularization\n",
        "\n",
        "model = Model(inputs=input_tensor, outputs=output_tensor)  # Create the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), metrics=['accuracy'])\n",
        "\n",
        "# Prepare the data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest',\n",
        "                                   validation_split=0.2)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory('/content/gdrive/My Drive/DL project_aug1/DL project/training',\n",
        "                                                    target_size=(image_size, image_size),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='sparse',\n",
        "                                                    subset='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory('/content/gdrive/My Drive/DL project_aug1/DL project/testing',\n",
        "                                                         target_size=(image_size, image_size),\n",
        "                                                         batch_size=32,\n",
        "                                                         class_mode='sparse',\n",
        "                                                         subset='validation')\n",
        "\n",
        "# Fiting the model\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "                    epochs=20,\n",
        "                    callbacks=[tensorboard, es, lr_scheduler])\n",
        "\n",
        "# Evaluate the model\n",
        "scores = model.evaluate(validation_generator, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n",
        "\n",
        "# Generate classification report\n",
        "y_pred = model.predict(validation_generator, batch_size=64, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "print(classification_report(validation_generator.classes, y_pred_bool, target_names=train_generator.class_indices.keys()))\n",
        "\n",
        "# Save the model\n",
        "model.save(\"ViT_model_improved.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlUjzT8EQlJy",
        "outputId": "c5cd7d22-d4e1-40bf-e3c4-615eef0457c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/DL project_aug1/DL project\n",
            "ResNet50\t       testing\t ViT\t       X_test.pickle   Y_test.pickle\n",
            "ResNet50accuracy87.h5  training  ViT_model.h5  X_train.pickle  Y_train.pickle\n",
            "Found 2297 images belonging to 4 classes.\n",
            "Found 78 images belonging to 4 classes.\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1633s\u001b[0m 23s/step - accuracy: 0.2121 - loss: 4.0102 - val_accuracy: 0.2812 - val_loss: 1.8632 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m 1/71\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24:45\u001b[0m 21s/step - accuracy: 0.3125 - loss: 2.7345"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 1s/step - accuracy: 0.3125 - loss: 2.7345 - val_accuracy: 0.3571 - val_loss: 2.0103 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1625s\u001b[0m 22s/step - accuracy: 0.3141 - loss: 2.8395 - val_accuracy: 0.3125 - val_loss: 1.8880 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 115ms/step - accuracy: 0.4062 - loss: 2.4287 - val_accuracy: 0.0714 - val_loss: 2.3895 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1605s\u001b[0m 22s/step - accuracy: 0.3587 - loss: 2.6508 - val_accuracy: 0.3750 - val_loss: 1.7806 - learning_rate: 5.0000e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 113ms/step - accuracy: 0.3750 - loss: 2.6169 - val_accuracy: 0.4286 - val_loss: 2.0449 - learning_rate: 5.0000e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1611s\u001b[0m 22s/step - accuracy: 0.3751 - loss: 2.4474 - val_accuracy: 0.2812 - val_loss: 1.9658 - learning_rate: 5.0000e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 142ms/step - accuracy: 0.3750 - loss: 2.1614 - val_accuracy: 0.2143 - val_loss: 1.6557 - learning_rate: 5.0000e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1566s\u001b[0m 22s/step - accuracy: 0.3829 - loss: 2.3823 - val_accuracy: 0.3438 - val_loss: 1.8352 - learning_rate: 5.0000e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 173ms/step - accuracy: 0.3125 - loss: 1.9485 - val_accuracy: 0.3571 - val_loss: 1.4824 - learning_rate: 5.0000e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1619s\u001b[0m 22s/step - accuracy: 0.3894 - loss: 2.2183 - val_accuracy: 0.4375 - val_loss: 1.6753 - learning_rate: 5.0000e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 142ms/step - accuracy: 0.3750 - loss: 2.6104 - val_accuracy: 0.4286 - val_loss: 1.5560 - learning_rate: 5.0000e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1600s\u001b[0m 22s/step - accuracy: 0.4187 - loss: 2.1505 - val_accuracy: 0.4062 - val_loss: 1.6693 - learning_rate: 5.0000e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 141ms/step - accuracy: 0.4688 - loss: 1.8800 - val_accuracy: 0.2857 - val_loss: 1.6958 - learning_rate: 2.5000e-05\n",
            "Epoch 15/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1624s\u001b[0m 22s/step - accuracy: 0.4303 - loss: 1.9900 - val_accuracy: 0.3906 - val_loss: 1.5027 - learning_rate: 2.5000e-05\n",
            "Epoch 15: early stopping\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 15s/step - accuracy: 0.4395 - loss: 1.5869\n",
            "Test loss: 1.7247323989868164\n",
            "Test accuracy: 0.41025641560554504\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 17s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      glioma       0.36      0.20      0.26        20\n",
            "  meningioma       0.20      0.17      0.19        23\n",
            "    no_tumor       0.09      0.05      0.06        21\n",
            "   pituitary       0.14      0.36      0.20        14\n",
            "\n",
            "    accuracy                           0.18        78\n",
            "   macro avg       0.20      0.19      0.18        78\n",
            "weighted avg       0.20      0.18      0.17        78\n",
            "\n"
          ]
        }
      ]
    }
  ]
}